---
layout: default
title: Deep Learning for NLP
menu: no
---

We also read about deep learning (even when latent variables are nowhere to be seen).

# Scheduled

* Friday 30: [Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation](https://arxiv.org/pdf/1308.3432.pdf) and Gumbel relaxations ([a](https://arxiv.org/abs/1611.00712) and [b](https://arxiv.org/pdf/1611.01144.pdf))

# Pool

* [Pointer Networks](https://arxiv.org/pdf/1506.03134.pdf)
* [Key-Value Memory Networks for Directly Reading Documents](https://arxiv.org/pdf/1606.03126.pdf)

# Done

* June 15: [Attention is all you need](https://arxiv.org/pdf/1706.03762.pdf)
* June 9: [Learning Structured Text Representations](https://arxiv.org/pdf/1705.09207.pdf) and [Structured Attention Networks](https://arxiv.org/pdf/1702.00887.pdf)
* May 17: [Frustratingly Short Attention Spans in Neural Language Modeling](https://arxiv.org/pdf/1702.04521.pdf)
