---
layout: default
title: Bayesian Neural Networks
menu: no
---

<iframe src="https://calendar.google.com/calendar/embed?mode=AGENDA&amp;height=250&amp;wkst=1&amp;bgcolor=%23FFFFFF&amp;src=c752525tganmcbvhfl1tu2b9vo%40group.calendar.google.com&amp;color=%230D7813&amp;ctz=Europe%2FAmsterdam" style="border-width:0" width="600" height="250" frameborder="0" scrolling="no"></iframe>


# Schedule

* 04/07/2018 11am F2.02: [Variational Dropout and the Local Reparameterization Trick](//papers.nips.cc/paper/5666-variational-dropout-and-the-local-reparameterization-trick.pdf)
    * Further reading: 
        * Sparse Variational Dropout: [paper](//arxiv.org/pdf/1701.05369) and [talk](//vimeo.com/238221185)
        * [Variational Gaussian Dropout is not Bayesian](//arxiv.org/pdf/1711.02989.pdf)
* 27/06/18 11am F2.02: [Dropout as a Bayesian Approximation: Appendix](//arxiv.org/pdf/1506.02157.pdf)
    * Background:
        * Hinton's dropout: [arxiv](//arxiv.org/pdf/1207.0580.pdf) and [JMLR](//jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf)

# History of Bayesian NNs 

* Early 90s: McKay [I](//www.mitpressjournals.org/doi/pdf/10.1162/neco.1992.4.3.448), [II](//www.mitpressjournals.org/doi/pdf/10.1162/neco.1992.4.3.415), and [III](//www.mitpressjournals.org/doi/pdf/10.1162/neco.1992.4.5.720) 
* [Neal, 1995](//www.cs.toronto.edu/~radford/ftp/thesis.pdf)
* [Williams, 1997](//papers.nips.cc/paper/1197-computing-with-infinite-networks.pdf)
* [Barber and Bishop, 1998](//www.microsoft.com/en-us/research/wp-content/uploads/2016/02/bishop-ensemble-nato-98.pdf)
* Check [Section 2.2 of Gal's thesis](//mlg.eng.cam.ac.uk/yarin/thesis/thesis.pdf)


## David McKay's

* [Density Networks](https://pdfs.semanticscholar.org/8734/b13a74765d4a78ebf15c9c38991a5302d71c.pdf)
* [Bayesian Neural Networks and Density Networks](http://www.inference.org.uk/mackay/ch_learning.pdf)
* [Neural Networks Summer School](http://www.inference.org.uk/mackay/cpi4.pdf)

# Pool

* [Weight Uncertainty in Neural Networks](https://arxiv.org/pdf/1505.05424.pdf)
* [Bayesian Recurrent Neural Networks](https://arxiv.org/pdf/1704.02798.pdf)
* [Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning](https://arxiv.org/pdf/1506.02142.pdf)
* [On Modern Deep Learning and Variational Inference](http://www.approximateinference.org/accepted/GalGhahramani2015.pdf)
* [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](http://papers.nips.cc/paper/6241-a-theoretically-grounded-application-of-dropout-in-recurrent-neural-networks.pdf)
* [Scalable Bayesian Learning of Recurrent Neural Networks for Language Modeling](http://www.aclweb.org/anthology/P17-1030)

