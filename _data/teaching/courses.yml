-
  layout: course
  selected: y
  year: 2017
  event: 2018-present (offered in Winter)
  img: nlmi
  title: Natural Language Models and Interfaces
  doc-url: //uva-slpl.github.io/nlmi/
  institution: UvA
  github: uva-slpl/nlmi
  about: | 
    I coordinate and teach Natural Language Models and Interfaces. This is a second-year course offered to students in the Bachelor's in Artificial Intelligence programme of the University of Amsterdam. The course covers some of the essential techniques in natural language processing with a focus on language modelling and word representation:

    * Review of probability theory
    * Probability of a setence
    * Markov Models and n-gram language modelling
    * Hidden Markov Models and part of speech tagging
    * Probabilistic context-free grammars 
    * Locally normalised log-linear models
    * Distributional semantics and neural models of word representation
    * Overview of NLP applications

-
  layout: course
  selected: y
  year: 2017
  event: 2015-present (offered in Spring)
  img: nlp2
  title: Natural Language Processing II
  doc-url: //uva-slpl.github.io/nlp2/
  institution: UvA
  github: uva-slpl/nlp2 
  about: |
    I organise and teach Natural Language Processing II at UvA (the course is focused on machine translation). This is the third edition which I organise, the first one was in the spring of 2015. 

    The course is organised in three blocks

    * Unsupervised word alignments: directed models (EM estimation and VB) and undirected models (MLE via gradient-based optimisation)
    * Statistical machine translation: (hierarchical) phrase-based MT (linear models), latent-variable CRF for hierarhical PBSMT
    * Neural machine translation: fully supervised sequence to sequence models, deep generative models
-
  layout: course
  selected: y
  year: 2017
  event: March 2017 - 6EC
  img: bpcfg
  title: Bayesian inference for PCFGs
  doc-url: /resources/courses/pcfgs.pdf
  institution: UvA
  about: |
    4 weeks course on Bayesian inference for PCFGs, here is a list of the topics covered:

    * [Parsing as weighted deduction](https://arxiv.org/pdf/cmp-lg/9404008.pdf) (CKY, Earley)
    * [Inside-Outside and ancestral sampling](http://www.aclweb.org/anthology/J/J99/J99-4004.pdf)
    * [Maximum likelihood of PCFGs via EM](https://www.cs.jhu.edu/~jason/665/lari-young.pdf)
    * Introduction to Dirichlet distribution and related processes
    * [Bayesian inference for PCFG](https://cocosci.berkeley.edu/tom/papers/mcmc-pcfg.pdf): Gibbs sampler and collapsed Metropolis-Hastings sampler

    My student [Daan van Stigt](//github.com/daandouwe) did an excellent job! Check his amazing [notebooks](//github.com/daandouwe/Probabilistic-modelling-with-PCFG).

-
  layout: course
  selected: y
  year: 2015
  event: June 2015 - 6EC
  img: deduction
  title: Parsing as deduction and Monte Carlo sampling for PCFGs
  doc-url: /resources/courses/MoL-pcfg-sampling.pdf
  institution: UvA
  github: wilkeraziz/notebooks/tree/master/MoL_June15
  about: |
    4 weeks course on MC techniques for PCFGs, here is a list of the topics covered:

    * [Parsing as weighted deduction](https://arxiv.org/pdf/cmp-lg/9404008.pdf) (CKY, Earley)
    * [Inside-Outside](http://www.aclweb.org/anthology/J/J99/J99-4004.pdf)
    * [Ancestral sampling](http://dl.acm.org/citation.cfm?id=748109)
    * [Slice sampling](http://www.aclweb.org/anthology/N10-1028)

